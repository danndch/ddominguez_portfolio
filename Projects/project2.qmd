---
title: "Senior Project"
subtitle: "Data Products"
author: "Daniel Dominguez"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-float:
      floated: true
      smooth-scroll: true
      toc-styles:
        width: 20%
        height: auto
        overflow: auto
        position: fixed
        right: 0
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

# Data Products and its' parts

A data product in Data Science is a product that facilitates an end goal through the use of data. It is essentially a technical asset that makes use of data as its core component to solve a specific problem or fulfill a particular need for its users. Data products can be as simple as a report generated from data analyses, or as complex as a machine learning model that powers a recommendation system in an application.

Data products are the bridge between raw data and practical applications. They are essential for applying the theoretical aspects of data science to solve real-world problems. By turning data into actionable insights, data products enable businesses and organizations to make informed decisions, optimize operations, and enhance user experiences. As such, the development and management of data products is a crucial aspect of the data science field, requiring a blend of technical skills, domain expertise, and an understanding of user needs.

## The key characteristics of a data product include:

* Data-Driven: At its core, a data product uses data to function. This data can be static or dynamic, and the product's effectiveness often depends on the quality and relevance of this data.

* Actionable Insights: Unlike raw data or basic analyses, a data product provides insights that are actionable. This means that users can make decisions or take actions based on the output of the data product.

* User-Focused: Data products are designed with the end-user in mind, ensuring that they are accessible, understandable, and valuable to the intended audience. This often involves user interface design, data visualization, and user experience optimization.

* Automated: Many data products automate processes that would otherwise require manual data analysis, saving time and reducing the potential for human error.

* Scalable: As data grows or as the number of users increases, a well-designed data product can scale to accommodate these changes without losing performance or reliability.


## SQL

Diving into SQL (Structured Query Language) is like learning the grammar of data speak. It's the go to language for communicate to databases, asking them about the information they hold. Whether you're inquiring about customer behaviors, financial transactions, or anything in between, SQL helps you pose the questions and understand the responses. With SQL, you can sift through mountains of data to find the nuggets of insight that drive strategies and decisions, all of this is always done by a few well-crafted queries.

## A little visit down memory lane with SQL
The key parts of an SQL query provides a deeper understanding of how data is manipulated and retrieved from a database. Each component plays a crucial role in shaping the output of the query.

### SELECT
The SELECT statement specifies the columns of data you want to retrieve from one or more tables in a database. It's the starting point of most queries and defines which fields should be included in the output. You can use SELECT * to retrieve all columns or specify individual column names separated by commas for a more tailored output.

Example:

SELECT FirstName, LastName <br>
FROM Employees; <br>

This query retrieves the FirstName and LastName columns from the Employees table.

### FROM/JOIN
The FROM clause specifies the table(s) from which to retrieve data. When data needs to be combined from multiple tables, the JOIN clause is used. There are several types of joins, including INNER JOIN, LEFT JOIN, RIGHT JOIN, and FULL JOIN, each serving different purposes in terms of how tables are merged based on matching data in specified columns.

Example:

SELECT Orders.OrderID, Customers.CustomerName <br>
FROM Orders <br>
INNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID; <br>

This query retrieves order IDs from the Orders table and the corresponding customer names by joining the Orders table with the Customers table on the CustomerID column.

### WHERE
The WHERE clause filters records to include only those that meet certain conditions. It helps in narrowing down the results based on specified criteria, making the query output more relevant.

Example:

SELECT * <br>
FROM Employees <br>
WHERE Department = 'Marketing';<br>

This query retrieves all columns for employees who work in the Marketing department.

### HAVING
The HAVING clause is used to filter groups of rows after they've been grouped by a GROUP BY clause. It's similar to the WHERE clause but is applicable to aggregated data. HAVING is commonly used with functions like SUM(), AVG(), COUNT(), etc.

Example:

  SELECT Department, COUNT(EmployeeID) AS NumberOfEmployees <br>
  FROM Employees <br>
  GROUP BY Department <br>
  HAVING COUNT(EmployeeID) > 10; <br>

This query counts the number of employees in each department and only includes those departments with more than 10 employees.

### GROUP BY
The GROUP BY clause groups rows that have the same values in specified columns into summary rows, like "find the number of employees in each department". It is often used with aggregate functions (COUNT(), MAX(), SUM(), AVG()).

Example:

  SELECT Department, AVG(Salary) AS AverageSalary <br>
  FROM Employees <br>
  GROUP BY Department; <br>

This query calculates the average salary within each department.

### ORDER BY
The ORDER BY clause is used to sort the result set of a query by one or more columns. It can sort the results in ascending (ASC) or descending (DESC) order. If no direction is specified, ASC is assumed by default.

Example:

 SELECT FirstName, LastName, Salary <br> 
 FROM Employees <br>
 ORDER BY Salary DESC; <br>

This query retrieves employee names and salaries, sorted by salary in descending order.

### LIMIT/OFFSET
The LIMIT clause is used to constrain the number of rows returned by a query. This is useful in large datasets to retrieve only a subset of rows. The OFFSET clause is used in conjunction with LIMIT to skip a specific number of rows before starting to return rows from the query.

Example:

 SELECT * <br>
 FROM Employees <br>
 LIMIT 10 OFFSET 5; <br>
This query skips the first 5 rows and then retrieves the next 10 rows from the Employees table.


## Subqueries
A subquery is a query embedded within another query. It can be used in various parts of the main query, including the SELECT, FROM, and WHERE clauses. Subqueries are typically enclosed in parentheses and can return scalar values, single columns, single rows, or tables, depending on their placement and purpose in the main query.

Example of a subquery in a WHERE clause:

SELECT * <br>
FROM Employees <br>
WHERE DepartmentID IN (SELECT DepartmentID FROM Departments WHERE Name = 'Research');<br>

In this example, the subquery selects DepartmentIDs from the Departments table where the department name is 'Research'. The main query then uses these IDs to filter employees from those specific departments.

## Nested Queries
A nested query refers to a broader category of queries that contain other queries, and it can encompass subqueries as one of its forms. The term "nested query" can also specifically refer to queries nested within FROM clauses, where a subquery is used to create a temporary table that the outer query can then join to or operate on.

Example of a nested query in a FROM clause:

 SELECT AvgSalaries.Department, Employee.Name, Employee.Salary <br>
 FROM Employees AS Employee <br>
 JOIN ( <br>
   SELECT DepartmentID, AVG(Salary) AS AverageSalary <br>
    FROM Employees <br>
   GROUP BY DepartmentID <br>
) AS AvgSalaries ON Employee.DepartmentID = AvgSalaries.DepartmentID <br>
WHERE Employee.Salary > AvgSalaries.AverageSalary; <br>

In this example, the nested query calculates the average salary per department and creates a temporary table (AvgSalaries) with this information. The outer query then selects employees who earn more than the average salary in their respective departments.

## Comparison

* Scope: Subqueries can be considered a specific type of nested query. While all subqueries are nested queries, not all nested queries are subqueries, especially when considering the broader use of nesting in SQL queries.
* Usage: Subqueries are often used for returning specific values that the main query can use for comparison or filtering, whereas nested queries, particularly those in the FROM clause, are used to create temporary tables for the main query to interact with.
* Complexity: Nested queries, especially those used as temporary tables, can be more complex and might involve aggregation, grouping, or additional joins within the nested part, whereas subqueries might be simpler, returning a single value or a set of values for the main query to use.
* In summary, while the terms subquery and nested query are often used interchangeably, the distinction usually lies in the specific use case and complexity. Subqueries are a subset of nested queries, primarily used within WHERE, SELECT, and FROM clauses for filtering, selection, or temporary table creation.


## APIs
Application Programming Interfaces (APIs) serve as the conduit through which different software systems interact, based on a set of defined protocols and rules. APIs facilitate the seamless exchange of data and functionality between disparate systems, making them integral to modern software development.

### Components of an API Call:

Endpoint: The specific URL where the API can be accessed. It represents the specific function or resource you wish to interact with.
Headers: Contain metadata for the API call, such as content type, response format, and authentication tokens (API keys).
Body: Essential for POST or PUT requests, the body contains the data to be sent to the API.
Example: Consider a weather forecasting application that uses a third-party API to fetch weather data. The application might make a GET request to https://api.weather.com/v2/forecast?location=NewYork with headers containing an API key. The response could include data like temperature, humidity, and forecasts, which the application then displays to the user.

### Advantages of Using APIs:

Integration: APIs enable seamless integration of third-party services or data, enriching your application's capabilities without the need for extensive development.
Automation: Tasks can be automated by scripting interactions with APIs, saving time and reducing the potential for human error.
Flexibility: APIs allow for the extension of an application's functionality, enabling customization and scalability.
The Pipeline from the API or Server
A data pipeline is an orchestrated set of operations designed to move and transform data from its source to a destination, such as a database or data warehouse. It typically involves stages like data extraction, transformation, and loading (ETL).

## Stages of a Data Pipeline:

Extraction: Data is gathered from various sources, which could include databases, APIs, or flat files.
Transformation: The raw data is cleaned, enriched, and transformed into a format suitable for analysis. This might involve filtering out irrelevant data, converting data types, or aggregating information.
Loading: The transformed data is stored in a structured form in a target system for further analysis or reporting.
Example: A retail company might extract sales data from its online and physical stores (via APIs or direct database access), transform the data to calculate total sales by region and category, and load the results into a data warehouse for analysis.

### Advantages of Data Pipelines:

* Efficiency: Automating the flow of data reduces manual tasks and speeds up data processing.
* Consistency: Ensures that all data is processed in a uniform manner, improving data quality and reliability.
* Scalability: Can handle increasing volumes of data by scaling resources up or down as needed.

## Pushing Back Data to a Server, Data Warehouse, or Data Mart
After processing and analysis, data often needs to be stored in a structured and accessible form. This could involve:

* Updating an operational database to reflect new insights or changes.
* Storing aggregated or analyzed data in a data warehouse, making it available for complex queries and strategic decision-making.
* Creating data marts, which are subsets of data warehouses tailored to the specific needs of different departments or functions.

Example: After analyzing sales data, a business might update its inventory database to reflect items that need restocking. It might also store detailed sales analysis in a data warehouse for use in strategic planning and create a marketing-specific data mart focusing on customer purchase patterns.

Advantages:

*  Accessibility: Storing processed data makes it readily accessible for decision-making, reporting, and further analysis.
* Performance: Separating operational databases from analytical stores (data warehouses) improves performance in both systems.
* Security: Data warehouses and marts can implement specific security measures appropriate for the sensitivity of the stored data.

## Important parts of Machine Learning

### Data Enrichment
Data Enrichment is the process of augmenting your existing dataset with additional data from external sources to provide more context and depth. For instance, adding socioeconomic data to customer profiles can offer more insights into customer behavior and preferences.

Advantages:

Enhanced Insights: Provides a more rounded view of the data subjects, leading to more accurate analyses and predictions.
Improved Decision Making: Deeper data context can lead to better-informed strategic decisions.


### Feature Engineering
Feature Engineering involves creating new features from raw data to improve the performance of machine learning models. Techniques might include aggregating data points, decomposing features (e.g., splitting dates into day and month), or transforming variables (e.g., log transformations).

Advantages:

Model Accuracy: Properly engineered features can significantly improve model performance.
Interpretability: Well-chosen features can make models more understandable by highlighting the underlying factors that drive predictions.

### Data Enrichment vs Feature Engineering
While both processes aim to improve data quality, data enrichment broadens the dataset with new data, providing more dimensions for analysis. Feature engineering, on the other hand, works on the existing dataset, transforming it into a more model-friendly format. The choice between them depends on whether the need is for more data or for transforming existing data into a more useful form. Both are crucial in different stages of the data preparation process for machine learning.


# Sources

https://learning.oreilly.com/playlists/102dbc35-5c2c-47a2-9a9d-6711d369832e/



